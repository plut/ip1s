\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{math}
\usepackage[margin=20mm]{geometry}
\usepackage{graphicx}

\usepackage{unicode}
\def\bigperp{\mathop{\vcenter{\hbox{\scalebox{2}{\ensuremath{\perp}}}}}%
  \displaylimits}
\let\fr\mathfrak


\begin{document}
\title{IP1S in the non-cyclic case}
\subtitle{\verb+$Id$+}
\maketitle

\section{IP1S and symmetric matrices}


Let~$k$ be a field. We write a symmetric pencil~$S_{λ}$ as
\begin{equation}
S_{λ} = S_{∞} (λ + M).
\end{equation}
where $S_{∞}$ and~$S_{∞} M$ are symmetric matrices.

For any matrix~$M$ over the field~$k$, let
\begin{gather}
\ro S(M) = \acco { \text{$S$ symmetric such that $SM$~is symmetric} },\\
\ro C(M) = \text{commuting space of~$M$}.
\end{gather}

\begin{prop}
Let~$M$ be any matrix.
\begin{enumerate}
\item The set~$\ro S(M)$ contains an invertible matrix~$T$.
\item For any~$T ∈ \ro S(M)^{×}$ and any~$A$, $TA$~belongs to~$\ro S(M)$
if and only if $TA$~is symmetric and $A ∈ \ro C(M)$.
\item For any $S ∈ \ro S(M)$ and any~$X ∈ \ro C(M)$, $\transpose{X} S X ∈
\ro S(M)$.
\end{enumerate}
\end{prop}

More precisely, let~$S ∈ \ro S(M)$, $X ∈ \ro C(M)$, and~$S' =
\transpose{X} S X ∈ \ro S(M)$; we may then write~$S = TA$ and~$S' = TA'$
with~$A, A' ∈ \ro C(M)$. The relation between~$A$ and~$A'$ is then given
by
\begin{equation}
A' = X^{⋆} A X\qquad\text{where} \quad X^{⋆} = T^{-1} \transpose{X} T.
\end{equation}

The IP1S problem may be restated in the following way: given two
matrices~$A, B ∈ \ro C(M)$ such that~$TA$, $TB$ are symmetric, compute a
matrix~$X ∈ \ro C(M)^{×}$ such that~$B = X^{⋆} A X$. We solve this by
studying the algebra~$\ro C(M)$ and its involution~$X ↦ X^{⋆}$.

By using the primary decomposition of~$M$ as well as an extension of
scalars, we may assume that the minimal polynomial of~$M$ is a power
of~$x$. We compute the structure of~$\ro C(M)$ in this case below.

\section{Structure of the commuting space}
For each integers~$u ≥ v$, write $H_u$~for the companion matrix of the
polynomial~$x^u$ and define block matrices~$J_{u,v}$ and~$J_{v,u}$ by
\begin{equation}
J_{u,v} = \mat{ \mathrm{id}(v) \\ 0^{v ×(u-v)}},\quad
J_{v,u} = \mat{ 0^{(u-v)× v } & \mathrm{id}(v)}.
\end{equation}

\begin{prop}\label{prop:rel-HJ}
Let~$u, v, w$ be three integers.
\begin{enumerate}
\item $H_{u} J_{u,v} = J_{u,v} H_{v}$.
\item The space of all matrices~$A$ of size~$u × v$ such that~$H_u A
= A H_v$ is exactly $k[H_u] J_{u,v}$.
\item $J_{u,v} J_{v,u} = H_{u}^{\abs{u-v}}$.
\item $J_{u,v} J_{v,w} = H_u^{Δ} J_{v,w}$ where $Δ$~is the distance
between~$v$ and the interval~$[u,w]$.
\end{enumerate}
\end{prop}

Let~$n_1 ≥ … ≥ n_r$ be integers and~$n = ∑ n_i$.
For any~$(r, s)$, we write~$E_{r,s}$ for the $n × n$ matrix written as
blocks~$(e_{i,j})$ of size~$n_i × n_j$, such that~$e_{r,s} = J_{n_r,
n_s}$, and all other blocks are zero. We abuse notation: for any matrix
$A$ of size~$d × n_{r}$, we write $A E_{r,s}$ for the matrix of size~$d ×
n$ with entries~$(0, …, 0, A J_{n_r,n_s}, 0, …, 0)$.

\begin{prop}\label{prop:structure-commutant}
Let~$M$ be the block-diagonal matrix $M = ∑_{i} H_{n_i} E_{n_i,n_i}$.

The commuting space of~$M$ is the space of
all block matrices~$A = ∑ A_{i,j} E_{i,j}$, where $A_{i,j}$~belongs
to~$k[H_{n_i}] J_{n_{i}, n_{j}} = J_{n_i, n_j} k[H_{n_j}]$.
\end{prop}

Each entry~$A_{i,j}$ may be written as a polynomial
\begin{equation}
A_{i,j} = a_{i,j} (H_{n_i}) J_{n_i,n_j} = J_{n_i,n_j} a_{i,j} (H_{n_j})
\end{equation}
where $a_{i,j}(H) ∈ k[H]/H^{d_j}$.
We simplify the notation and write~$A = (a_{i,j})$ where~$a_{i,j} ∈
k[H]$. The rules of computation in the algebra~$\ro C(M)$ are given
below.

\begin{prop}
Let~$A, B$ be two elements of~$\ro C(M)$ with block coordinates~$(a_{i,j})$,
$(b_{i,j})$.
\begin{enumerate}
\item $A B$~has the block coordinates $(∑_{r} a_{i,r} b_{r,j} J^{d(n_r, [n_i,
n_j])})$.
\item $A^{⋆}$~has the block coordinates~$(a_{j,i})$. In particular,
$TA$~is symmetric exactly when $a_{j,i} = a_{i,j}$ for all~$(i,j)$.
\item
\[ \det A \;=\; ∏_{d ≥ 0} \det (a_{i,j} | n_{i} = n_j = d)^{d}. \]
\end{enumerate}
\end{prop}


\begin{prop}
The group~$\ro C(M)^{×}$ is generated by the following elements:
\begin{enumerate}
\item block-diagonal matrices~$∑ a_i E_{i,i}$ with~$a_i ∈
(k[J]/J^{d_i})^{×}$;
\item block shear matrices~$1 + a E_{i,j}$ with~$i ≠ j$, $a ∈ k[J]$;
\item block transposition matrices, of the form~$∑_i E_{i,τ(i)}$
where $τ$~is a transposition of two elements~$j,j'$ such that~$n_j =
n_{j'}$.
\end{enumerate}
\end{prop}

\begin{prop}
Let~$X = 1 + x E_{r,s} ∈ \ro C(M)$ and assume that~$A = A^{⋆} ∈ \ro
C(M)$. Then the automorphism~$A ↦ X^{⋆} A X$ of~$\ro C(M)$ is defined by
the equations
\begin{gather*}
a_{s,i} ← a_{s,i} + x H^{Δ_i} a_{r,i},\\
a_{s,s} ← a_{s,s} + H^{Δ_{s}} ( 2x a_{r,s} + x^2 a_{r,r}),
\end{gather*}
where~$Δ_{i} = \mathrm{dist} (n_{r}, [n_s, n_i])$.
\end{prop}

\section{Classifying quadratic forms}

\subsection{Quadratic forms over the local ring}

The ring~$R = k[H]/H^n$ is a local ring with maximal ideal~$JR$. For
all~$b ∈ R$ and~$d ∈ ℕ$, let~$q_b^{(r)}$~be the quadratic form~$x_1^2 + …
+ x_{r-1}^2 + b x_r^2$. Then according to~\cite[91--92]{omeara}, any
quadratic space~$V$ of dimension~$d$ on~$R$ has a Jordan decomposition:
it is isomorphic to an orthogonal direct sum
\begin{equation}
V ≃ \bigperp_{i ≥ 0} H^i q_{δ_i}^{(d_i)},
\end{equation}
where~$δ_i ∈ k^{×}/k^{×2} = \acco {1, δ}$ and~$∑ d_i = d$. The reduction
algorithm is detailed in the next paragraph.

\subsection{The case $(n_1 = n_2 = … = n_r)$}

Assume that~$n_1 = … = n_r$ and~$n = r n_1$. Let~$R = k[H]/H^{n_1}$. Then
the pencil~$S$ is determined by the quadratic form~$A = (a_{ij}(H))_{i,j
= 1…r}$ on the $R$-module~$V = R^r$.

Let~$\fr a$ be the ideal of~$R$ generated by the coefficients of~$A$.
Since $R$~is local, there exists~$v_1 ∈ V$ such that $A(v_1)$ generates
the ideal~$\fr a$; then using the orthogonal decomposition~$x_1 R ⊕
x_1^{⟂}$ recursively, we find a decomposition~$V = ⨁ V_i$ such
that~$A|_{V_i} = H^i A_i$, where $A_i$~is non-singular on~$V_i$. Using
Gaussian reduction, we then find that~$A_i$~is isometric to either the
identity scalar product~$∑ x_i y_i$, or the twisted scalar product~$x_1
y_1 + … + x_{d_{i}-1} y_{d_i-1} + δ x_{d_i} y_{d_i}$.


\subsection{The case~$(n_1 > n_2)$}

We investigate the case where the matrix~$M$ has exactly two
blocks~$H_{n_1}$ and~$H_{n_2}$ with~$n_1 > n_2$. Let~$e = n_1 - n_2$ and
write~$A$ as a block matrix~$\mat{a & bJ_{n_1,n_2} \\ b J_{n_2,n_1} & c}$
and let~$X = (x_{ij})$ be an element of~$\ro C(M)$. Let~$R_1 =
k[H]/H^{d_1}$; write~$f(A) = \mat{a & b H^e \\ b H^e & c H^e}$ and~$g(X)
= \mat{x_{11} & H^e x_{12} \\ x_{21} & x_{22}}$ as matrices
in~$R_1^{2×2}$; then one checks that
\begin{equation}
f(X^{⋆} A X) = \transpose{g(X)} f(A) g(X).
\end{equation}
Let~$S_e$ be the image by~$f$ of the space of symmetric matrices
and~$G_e$ be the image by~$g$ of the group of invertible matrices. Then
the equivalence classes of quadratic pencils with characteristic
endomorphism~$M$ correspond bijectively to the elements of~$S_e / G_e$.

Let $R = k[[H]]$, $K = k[[H]]$; for~$a,b,c ∈ R$, let~$L = K[θ] / (a θ^2 +
b θ + c)$. The quadratic form determined by the element~$(a,H^e b, H^e
c)$ of~$S_e$ is isometric to the norm form~$(x,y) ↦ N(x + y θ)$ on the
fractional ideal~$(1, θ)$ of~$L$.

\begin{thebibliography}{99}
\bibitem{omeara} Timothy O'Meara, \emph{Introduction to quadratic forms}.
\bibitem{milnorhusemoller} H. Milnor, D. Husemoller, \emph{Symmetric
bilinear forms}.
\end{thebibliography}
\end{document}
